data <- read.csv("C:/subj/AllParticipantData_comp_CFQCAARS.csv", header=T)
#Look at Column names:
colnames(data)
#Rename some of the columns how I like them:
data<-rename(data, c("ResponseTime"="RT", "ResponseStatus"="Accuracy", "X"="subject"))
#Remove the one row that has a NAs:
data<-data[complete.cases(data$RT),]
#Check number of Trials for each participant by running the function 'length',
#on "data$RT", broken down by ID
num_trials1 <- ddply(data, c("ID"), summarise,
Trials    = length(RT))
#Have a look at this
summary(num_trials1$Trials)#so everybody has 320 trials to start with
#Calculate each participant's accuracy as a %
Accuracy_checker <- ddply(data, c("ID"), summarise,
Hits  = sum(Accuracy=="Correct"),
Misses = sum(Accuracy=="Incorrect"))
Accuracy_checker$Total=Accuracy_checker$Hits+Accuracy_checker$Misses
Accuracy_checker$Accuracy=(Accuracy_checker$Hits/Accuracy_checker$Total)*100
summary(Accuracy_checker$Accuracy)
#Plot the accuracy distribution
hist(Accuracy_checker$Accuracy)
#This task has 50% chance of guessing each trial correctly
#a binom.test shows that participants must have at least 179 correct out of
#the 320 trials in order for us to be 95% confident that they were not guessing
#the answer
binom.test(x=179, n=320, p=0.5)
#Most participant's have greater than 178 trials correct, check who doesn't:
ThoseGuessing<-Accuracy_checker[Accuracy_checker$Hits<178,]
ThoseGuessing
#make a new logical column in the main dataframe for whether each
#participant was guessing or not (TRUE/FALSE):
for (i in 1:length(data$ID)) {
data$guessing[i]<-any(ThoseGuessing$ID==data$ID[i])
}
#Make the required factors:
data$ID <- factor(data$ID)
data$SetSize <- factor(data$SetSize)
data$TargetHem <- factor(data$TargetHem)
data$TargetLoc <- factor(data$TargetLoc)
data$DisplayType <- factor(data$DisplayType)
data$TargetType <- factor(data$TargetType)
data$Trial <- factor(data$Trial)
data$Site <- factor(data$Site)
data$dat1utr <- factor(data$dat1utr)
data$dat1i8 <- factor(data$dat1i8)
data$dat1haplo <- factor(data$dat1haplo)
data$drd4 <- factor(data$drd4)
#Cognitive failures
data$CFQ <-factor(data$CFQ)
#CAARS Inattention
data$CAARS_A <-factor(data$CAARS_A)
#CAARS hyperactivity
data$CAARS_B <-factor(data$CAARS_B)
#CAARS ADHD total
data$CAARS_H <-factor(data$CAARS_H)
#Rename factor Levels:
data$TargetHem <- revalue(data$TargetHem, c("1"="Left", "2"="Right")) #Hi Beth, please just check this is correct i.e. that "1" does indeed stand for "Left" here
data$DisplayType <- revalue(data$DisplayType, c("1"="Unilateral", "2"="Bilateral")) #Beth also better double check that "1" was actually "Unilateral
data$SetSize <- revalue(data$SetSize , c("4"="Four", "8"="Eight"))
data$dat1utr<- revalue(data$dat1utr, c("#N/A"=NA, "0"="zero","1"="one","2"="two")) #change the "#N/A" to R's system NA
data$CFQ<- revalue(data$CFQ, c("#N/A"=NA)) #change the "#N/A" to R's system NA
data$CAARS_A<- revalue(data$CAARS_A, c("#N/A"=NA)) #change the "#N/A" to R's system NA
data$CAARS_B<- revalue(data$CAARS_B, c("#N/A"=NA)) #change the "#N/A" to R's system NA
data$CAARS_H<- revalue(data$CAARS_H, c("#N/A"=NA)) #change the "#N/A" to R's system NA
#Look at RT distribution for each DAT1 group
#Now kick out those participants who were guessing
#Kick out trials with stim. timing problems
data<-data[data$Timing.Status=="OK",]
#Remove incorrect trials
data<-data[data$Accuracy=="Correct",]
#Remove trials where RT too fast
data<-data[!data$RT<200,]
#....or too slow to be real RTs
data<-data[!data$RT>2000,]
#Now have a look at the RT distribution:
hist(data$RT)
data$log_RT<-log(data$RT) #log
hist(data$log_RT)
#####Z-score each participant's log(RT) data inside the task Conditions####
data$IDbySetSizebyDisplayType<-interaction(data$ID, data$SetSize, data$DisplayType) #ID by SetSize by DisplayType
#calculate mean and sd
m <- tapply(data$log_RT,data$IDbySetSizebyDisplayType,mean)
s <- sqrt(tapply(data$log_RT,data$IDbySetSizebyDisplayType,var))
#calculate RT.Z and save it inside data.frame
data$RT.Z <- (data$log_RT-m[data$IDbySetSizebyDisplayType])/s[data$IDbySetSizebyDisplayType]
#check that Z scores have mean=0 and std=1
RT.Z_checker <- ddply(data, c("ID", "SetSize", "DisplayType"), summarise,
N    = length(RT.Z ),
mean = round(mean(RT.Z )),
sd   = sd(RT.Z ),
se   = sd / sqrt(N))
#Check to make sure the z-transformation worked (i.e. should see Z mean=0 and SD=1)
summary(RT.Z_checker$mean)
summary(RT.Z_checker$sd)
##Remove trials where absolute RT.Z>3 (i.e. remove outlier RTs)
data<-data[!abs(data$RT.Z)>3,]
#Plot log(RT) historgam again after outlier removal
hist(data$log_RT)
#Check number of Trials for each participant by running the function 'length',
#on "data$RT" for each group, broken down by ID
num_trials2 <- ddply(data, c("ID"), summarise,
Trials    = length(RT))
summary(num_trials2$Trials)
#Plot the distribution of each participant's number of trials
#left after kicking out Incorrect and too fast/slow trials:
hist(num_trials2$Trials)
## Kick out subjects based on CFQ and CAARS scores
## (need to actually import these scores, but for now just kick out those who
##  I know have bad CFQ and CAARS scores from previous J.Neuro paper)
toBeRemoved<-which(data$subject=="subject240" | data$subject=="subject341" | data$subject=="subject358" | data$subject=="subject241")
data<-data[-toBeRemoved,]
#Calculate Distracter Hemifield (DistHem) as used in the
#Newman et al. (2014) JoN paper, rather then using TargetHem:
data$TargetHembyDisplayType<-interaction(data$TargetHem, data$DisplayType)
data$DistHem <- revalue(data$TargetHembyDisplayType, c("Left.Unilateral"="Left", "Left.Bilateral"="Right", "Right.Unilateral"="Right", "Right.Bilateral"="Left"))
#Remove the DAT1 rows that are NA:
data2<-data[complete.cases(data$dat1utr),]
#Remove the CFQ rows that are NA:
data2<-data[complete.cases(data$CFQ),]
#Remove the CAARS (total ADHD) rows that are NA:
data2<-data[complete.cases(data$CAARS_H),]
summary(data2$Site) #Summarize numbers once NAs are excluded
Test if ID is nested within dat1utr Genotype:
with(data2, isNested(ID,dat1utr)) #Yes it is because each participant (ID) can only
#belong to one dat1utr group (i.e. you can't be both 10/10 and 9/10 for dat1utr)
################################################################################################################
################Aggregate to mean instead of trial-by-trial and check for partcicipant-level outliers###########
############This will also alow me to calculate Set-size effect
############which can not be measured on the single trial level
############for obvious reasons.
DF_collapsed<-ddply(data2, .(ID, dat1utr, SetSize,TargetLoc,DisplayType,TargetHem, DistHem), summarise, RT=mean(RT))
ggplot(DF_collapsed, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ dat1utr)
ggplot(DF_collapsed, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ dat1utr)
istogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ dat1utr)
#####collapse to each participant so I can Z-score individual participants'
#####overall log(RT)s:
DF_collapsed_IDs<-ddply(data2, .(ID, dat1utr), summarise, RT=mean(RT))
DF_collapsed_IDs$RT.Z<-scale(DF_collapsed_IDs$RT)
ggplot(DF_collapsed_IDs, aes(RT.Z))  + geom_histogram(aes(y=..count..), colour="black", fill="white")
#Split by DAT1 group
ggplot(DF_collapsed_IDs, aes(RT, fill=dat1utr, colour=dat1utr)) + geom_density(alpha=.05)
View(DF_collapsed_IDs)
View(DF_collapsed_IDs)
View(data)
View(data)
View(data)
View(data)
data <- read.csv("C:/subj/AllParticipantData_comp_CFQCAARS.csv", header=T)
#beth change
####################################
######  FIRST TIME ONLY -
#####  Install some handy packages:
####  Remove the "# "in front of the line below and run the code. Replace the # after installing the packages, otherwise the R
#will reinstall the packates every time you run the script
#  install.packages(c("MASS", "robustbase", "robust", "mgcv", "scatterplot3d", "quantreg", "rrcov", "lars", "pwr", "mc2d", "psych",
#                     "Rfit","MBESS", "BayesFactor", "PoweR", "ggplot2", "reshape2", "plyr",
#                      "rmarkdown", "car", "gridExtra", "bootES", "BEST","foreign","nlme","pastecs","multcomp","ggplot2","compute.es"
#                     ,"ez","lattice","lme4","effects","diagram","png", "grid"))
## load relevant packages
library(foreign)
library(car)
library(ggplot2)
library(pastecs)
library(psych)
library(plyr)
library(multcomp)
library(reshape2)
library(compute.es)
library(ez)
library(lattice)
library(lme4)
library(png)
library(grid)
###### Import single trial data:
data <- read.csv("C:/subj/AllParticipantData_comp_CFQCAARS.csv", header=T)
#Look at Column names:
colnames(data)
#Rename some of the columns how I like them:
data<-rename(data, c("ResponseTime"="RT", "ResponseStatus"="Accuracy", "X"="subject"))
#Remove the one row that has a NAs:
data<-data[complete.cases(data$RT),]
#Check number of Trials for each participant by running the function 'length',
#on "data$RT", broken down by ID
num_trials1 <- ddply(data, c("ID"), summarise,
Trials    = length(RT))
#Have a look at this
summary(num_trials1$Trials)#so everybody has 320 trials to start with
#Calculate each participant's accuracy as a %
Accuracy_checker <- ddply(data, c("ID"), summarise,
Hits  = sum(Accuracy=="Correct"),
Misses = sum(Accuracy=="Incorrect"))
Accuracy_checker$Total=Accuracy_checker$Hits+Accuracy_checker$Misses
Accuracy_checker$Accuracy=(Accuracy_checker$Hits/Accuracy_checker$Total)*100
summary(Accuracy_checker$Accuracy)
#Plot the accuracy distribution
hist(Accuracy_checker$Accuracy)
#This task has 50% chance of guessing each trial correctly
#a binom.test shows that participants must have at least 179 correct out of
#the 320 trials in order for us to be 95% confident that they were not guessing
#the answer
binom.test(x=179, n=320, p=0.5)
#Most participant's have greater than 178 trials correct, check who doesn't:
ThoseGuessing<-Accuracy_checker[Accuracy_checker$Hits<178,]
ThoseGuessing
#make a new logical column in the main dataframe for whether each
#participant was guessing or not (TRUE/FALSE):
for (i in 1:length(data$ID)) {
data$guessing[i]<-any(ThoseGuessing$ID==data$ID[i])
}
#Make the required factors:
data$ID <- factor(data$ID)
data$SetSize <- factor(data$SetSize)
data$TargetHem <- factor(data$TargetHem)
data$TargetLoc <- factor(data$TargetLoc)
data$DisplayType <- factor(data$DisplayType)
data$TargetType <- factor(data$TargetType)
data$Trial <- factor(data$Trial)
data$Site <- factor(data$Site)
data$dat1utr <- factor(data$dat1utr)
data$dat1i8 <- factor(data$dat1i8)
data$dat1haplo <- factor(data$dat1haplo)
data$drd4 <- factor(data$drd4)
#Cognitive failures
data$CFQ <-factor(data$CFQ)
#CAARS Inattention
data$CAARS_A <-factor(data$CAARS_A)
#CAARS hyperactivity
data$CAARS_B <-factor(data$CAARS_B)
#CAARS ADHD total
data$CAARS_H <-factor(data$CAARS_H)
#Rename factor Levels:
data$TargetHem <- revalue(data$TargetHem, c("1"="Left", "2"="Right")) #Hi Beth, please just check this is correct i.e. that "1" does indeed stand for "Left" here
data$DisplayType <- revalue(data$DisplayType, c("1"="Unilateral", "2"="Bilateral")) #Beth also better double check that "1" was actually "Unilateral
data$SetSize <- revalue(data$SetSize , c("4"="Four", "8"="Eight"))
data$dat1utr<- revalue(data$dat1utr, c("#N/A"=NA, "0"="zero","1"="one","2"="two")) #change the "#N/A" to R's system NA
data$CFQ<- revalue(data$CFQ, c("#N/A"=NA)) #change the "#N/A" to R's system NA
data$CAARS_A<- revalue(data$CAARS_A, c("#N/A"=NA)) #change the "#N/A" to R's system NA
data$CAARS_B<- revalue(data$CAARS_B, c("#N/A"=NA)) #change the "#N/A" to R's system NA
data$CAARS_H<- revalue(data$CAARS_H, c("#N/A"=NA)) #change the "#N/A" to R's system NA
summary(data$CFQ)
summary(data$CAARS_H)
ribution for each DAT1 group
ggplot(data, aes(
ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ dat1utr)
#Remove trials where CFQ is NA
data<-data[!data$CFQ="NA",]
summary(data$CFQ)
summary(data$CFQ)
summary(data$CAARS_H)
clear
clc
#Set working directory
setwd(("//ad.monash.edu/home/User063/bethj/Documents/GitHub/CompTaskRepo"))
#beth change
####################################
######  FIRST TIME ONLY -
#####  Install some handy packages:
####  Remove the "# "in front of the line below and run the code. Replace the # after installing the packages, otherwise the R
#will reinstall the packates every time you run the script
#  install.packages(c("MASS", "robustbase", "robust", "mgcv", "scatterplot3d", "quantreg", "rrcov", "lars", "pwr", "mc2d", "psych",
#                     "Rfit","MBESS", "BayesFactor", "PoweR", "ggplot2", "reshape2", "plyr",
#                      "rmarkdown", "car", "gridExtra", "bootES", "BEST","foreign","nlme","pastecs","multcomp","ggplot2","compute.es"
#                     ,"ez","lattice","lme4","effects","diagram","png", "grid"))
## load relevant packages
library(foreign)
library(car)
library(ggplot2)
library(pastecs)
library(psych)
library(plyr)
library(multcomp)
library(reshape2)
library(compute.es)
library(ez)
library(lattice)
library(lme4)
library(png)
library(grid)
###### Import single trial data:
data <- read.csv("C:/subj/AllParticipantData_comp_CFQCAARS.csv", header=T)
#Look at Column names:
colnames(data)
#Rename some of the columns how I like them:
data<-rename(data, c("ResponseTime"="RT", "ResponseStatus"="Accuracy", "X"="subject"))
#Remove the one row that has a NAs:
data<-data[complete.cases(data$RT),]
#Check number of Trials for each participant by running the function 'length',
#on "data$RT", broken down by ID
num_trials1 <- ddply(data, c("ID"), summarise,
Trials    = length(RT))
#Have a look at this
summary(num_trials1$Trials)#so everybody has 320 trials to start with
#Calculate each participant's accuracy as a %
Accuracy_checker <- ddply(data, c("ID"), summarise,
Hits  = sum(Accuracy=="Correct"),
Misses = sum(Accuracy=="Incorrect"))
Accuracy_checker$Total=Accuracy_checker$Hits+Accuracy_checker$Misses
Accuracy_checker$Accuracy=(Accuracy_checker$Hits/Accuracy_checker$Total)*100
summary(Accuracy_checker$Accuracy)
#Plot the accuracy distribution
hist(Accuracy_checker$Accuracy)
#This task has 50% chance of guessing each trial correctly
#a binom.test shows that participants must have at least 179 correct out of
#the 320 trials in order for us to be 95% confident that they were not guessing
#the answer
binom.test(x=179, n=320, p=0.5)
#Most participant's have greater than 178 trials correct, check who doesn't:
ThoseGuessing<-Accuracy_checker[Accuracy_checker$Hits<178,]
ThoseGuessing
#make a new logical column in the main dataframe for whether each
#participant was guessing or not (TRUE/FALSE):
for (i in 1:length(data$ID)) {
data$guessing[i]<-any(ThoseGuessing$ID==data$ID[i])
}
#Make the required factors:
data$ID <- factor(data$ID)
data$SetSize <- factor(data$SetSize)
data$TargetHem <- factor(data$TargetHem)
data$TargetLoc <- factor(data$TargetLoc)
data$DisplayType <- factor(data$DisplayType)
data$TargetType <- factor(data$TargetType)
data$Trial <- factor(data$Trial)
data$Site <- factor(data$Site)
data$dat1utr <- factor(data$dat1utr)
data$dat1i8 <- factor(data$dat1i8)
data$dat1haplo <- factor(data$dat1haplo)
data$drd4 <- factor(data$drd4)
#Cognitive failures
data$CFQ <-factor(data$CFQ)
#CAARS Inattention
data$CAARS_A <-factor(data$CAARS_A)
#CAARS hyperactivity
data$CAARS_B <-factor(data$CAARS_B)
#CAARS ADHD total
data$CAARS_H <-factor(data$CAARS_H)
#Rename factor Levels:
data$TargetHem <- revalue(data$TargetHem, c("1"="Left", "2"="Right")) #Hi Beth, please just check this is correct i.e. that "1" does indeed stand for "Left" here
data$DisplayType <- revalue(data$DisplayType, c("1"="Unilateral", "2"="Bilateral")) #Beth also better double check that "1" was actually "Unilateral
data$SetSize <- revalue(data$SetSize , c("4"="Four", "8"="Eight"))
data$dat1utr<- revalue(data$dat1utr, c("#N/A"=NA, "0"="zero","1"="one","2"="two")) #change the "#N/A" to R's system NA
data$CFQ<- revalue(data$CFQ, c("#N/A"=NA)) #change the "#N/A" to R's system NA
data$CAARS_A<- revalue(data$CAARS_A, c("#N/A"=NA)) #change the "#N/A" to R's system NA
data$CAARS_B<- revalue(data$CAARS_B, c("#N/A"=NA)) #change the "#N/A" to R's system NA
data$CAARS_H<- revalue(data$CAARS_H, c("#N/A"=NA)) #change the "#N/A" to R's system NA
summary(data$CFQ)
summary(data$CAARS_H)
#Look at RT distribution for each DAT1 group
ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ dat1utr)
#Now kick out those participants who were guessing
data<-data[data$guessing!=TRUE,]
#Kick out trials with stim. timing problems
data<-data[data$Timing.Status=="OK",]
#Remove incorrect trials
data<-data[data$Accuracy=="Correct",]
#Remove trials where RT too fast
data<-data[!data$RT<200,]
#....or too slow to be real RTs
data<-data[!data$RT>2000,]
#Now have a look at the RT distribution:
hist(data$RT)
data$log_RT<-log(data$RT) #log
hist(data$log_RT)
#####Z-score each participant's log(RT) data inside the task Conditions####
data$IDbySetSizebyDisplayType<-interaction(data$ID, data$SetSize, data$DisplayType) #ID by SetSize by DisplayType
#calculate mean and sd
m <- tapply(data$log_RT,data$IDbySetSizebyDisplayType,mean)
s <- sqrt(tapply(data$log_RT,data$IDbySetSizebyDisplayType,var))
#calculate RT.Z and save it inside data.frame
data$RT.Z <- (data$log_RT-m[data$IDbySetSizebyDisplayType])/s[data$IDbySetSizebyDisplayType]
#check that Z scores have mean=0 and std=1
RT.Z_checker <- ddply(data, c("ID", "SetSize", "DisplayType"), summarise,
N    = length(RT.Z ),
mean = round(mean(RT.Z )),
sd   = sd(RT.Z ),
se   = sd / sqrt(N))
#Check to make sure the z-transformation worked (i.e. should see Z mean=0 and SD=1)
summary(RT.Z_checker$mean)
summary(RT.Z_checker$sd)
##Remove trials where absolute RT.Z>3 (i.e. remove outlier RTs)
data<-data[!abs(data$RT.Z)>3,]
#Plot log(RT) historgam again after outlier removal
hist(data$log_RT)
#Check number of Trials for each participant by running the function 'length',
#on "data$RT" for each group, broken down by ID
num_trials2 <- ddply(data, c("ID"), summarise,
Trials    = length(RT))
summary(num_trials2$Trials)
#Plot the distribution of each participant's number of trials
#left after kicking out Incorrect and too fast/slow trials:
hist(num_trials2$Trials)
## Kick out subjects based on CFQ and CAARS scores
## (need to actually import these scores, but for now just kick out those who
##  I know have bad CFQ and CAARS scores from previous J.Neuro paper)
toBeRemoved<-which(data$subject=="subject240" | data$subject=="subject341" | data$subject=="subject358" | data$subject=="subject241")
data<-data[-toBeRemoved,]
#Calculate Distracter Hemifield (DistHem) as used in the
#Newman et al. (2014) JoN paper, rather then using TargetHem:
data$TargetHembyDisplayType<-interaction(data$TargetHem, data$DisplayType)
data$DistHem <- revalue(data$TargetHembyDisplayType, c("Left.Unilateral"="Left", "Left.Bilateral"="Right", "Right.Unilateral"="Right", "Right.Bilateral"="Left"))
###########################################################################
#########################################################################
###Crossed vs Nested Factors:
#Test if ID is nested within Site:
with(data, isNested(ID,Site)) #SO yes, ID is nested within Site...
#Print a table of this nesting:
xtabs(~ ID + Site, data, drop = TRUE, sparse = TRUE)
# Because each Participant ("ID")" occurs within one and only one level of
# Site we say that ID is nested within Site
# The task factors (SetSize, TargetHem, DisplayType, etc) are crossed or
# partially crossed factors, "crossed" means that they have an observation for
# each combination level each of the other factors (some factors might be partially
# crossed in some participants if there is a lot of data missing due to bad accuracy)
# For Multilevel modeling with the lme4 package, nested factors are represended
# like this "(1 | Site/ID) - which means ID is nested inside
# Site", while crossed and partially cross factors are represented like
# this (1 |SetSize) +(1|TargetHem) +(1|DisplayType), etc.
########################################################################################################################
########################################################################################################################
########################################################################################################################
########################################################################################################################
# First as a sanity check, lets replicate the main finding from Figure 2A of
# Newman et al. (2014) JoN paper:
#Though at this point only the genotypes from Brisbane are included in the spreadsheet
#(no Monash genotypes included yet )and also there are no CAARS and CFQ data to
# use as covariates, so the results won't be exactly the same as
# Figure 2A of Newman et al. (2014) JoN paper, but the trend should still be there:
#Remove the DAT1 rows that are NA:
data2<-data[complete.cases(data$dat1utr),]
#Remove the CFQ rows that are NA:
data2<-data[complete.cases(data$CFQ),]
#Remove the CAARS (total ADHD) rows that are NA:
data2<-data[complete.cases(data$CAARS_H),]
summary(data2$Site) #Summarize numbers of NAs that have been excluded from the dataset
#Test if ID is nested within dat1utr Genotype:
with(data2, isNested(ID,dat1utr)) #Yes it is because each participant (ID) can only
#belong to one dat1utr group (i.e. you can't be both 10/10 and 9/10 for dat1utr)
################################################################################################################
################Aggregate to mean instead of trial-by-trial and check for partcicipant-level outliers###########
############This will also alow me to calculate Set-size effect
############which can not be measured on the single trial level
############for obvious reasons.
DF_collapsed<-ddply(data2, .(ID, dat1utr, SetSize,TargetLoc,DisplayType,TargetHem, DistHem), summarise, RT=mean(RT))
ggplot(DF_collapsed, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ dat1utr)
#####collapse to each participant so I can Z-score individual participants'
#####overall log(RT)s:
DF_collapsed_IDs<-ddply(data2, .(ID, dat1utr), summarise, RT=mean(RT))
DF_collapsed_IDs$RT.Z<-scale(DF_collapsed_IDs$RT)
ggplot(DF_collapsed_IDs, aes(RT.Z))  + geom_histogram(aes(y=..count..), colour="black", fill="white")
#Split by DAT1 group
ggplot(DF_collapsed_IDs, aes(RT, fill=dat1utr, colour=dat1utr)) + geom_density(alpha=.05)
# Calculate Set-size effect by DistHem
require(reshape2)
#Bring SetSize Factor up into wide formay to and calculate SetSize effect
DF_DistHem_wide <- dcast(DF_collapsed, ID + dat1utr + DisplayType + TargetHem + DistHem ~ SetSize, value.var="RT", fun.aggregate=mean)
#Calculate SetSize effect for each DistHem:
DF_DistHem_wide$SetSizeEffect<-DF_DistHem_wide$Eight - DF_DistHem_wide$Four
summary(DF_DistHem_wide$DistHem)
###Now try model DAT1 x DistHem in the collapsed setsize-effect data
random_intercepts_only_SetSizeDistHem<-lmer(SetSizeEffect ~ 1 + (1 | dat1utr/ID) +(1|DisplayType) + (1|DistHem), data = DF_DistHem_wide, na.action = na.omit, REML=FALSE)
DistHem<-update(random_intercepts_only_SetSizeDistHem, .~. + DistHem)
DAT1UTR<-update(DistHem, .~. + dat1utr)
DistHem_by_DAT1UTR<-update(DAT1UTR, .~. + dat1utr*DistHem)
anova(random_intercepts_only_SetSizeDistHem, DistHem, DAT1UTR, DistHem_by_DAT1UTR)
#So the DistHem_by_DAT1UTR effect is there, like in
# Newman et al. (2014) JoN paper, although at this point only the genotypes from
#Brisbane are included in the spreadsheet and also there are no CAARS and CFQ
#data to use as covariates, and also above  I've left in participants who performed poorly,
# so the results are not quite as strong (p=.05 instead of p=.004), but lets
# plot it to make sure the effect trends in the same direction:
source("summarySE.R")
source("summarySEwithin.R") #function to calculate Std.Er of mean
source("normDataWithin.R")
plotdata <- summarySEwithin(DF_DistHem_wide, measurevar="SetSizeEffect", withinvars=c("DistHem"), betweenvars="dat1utr", idvar="ID")
ggplot(plotdata, aes(x=DistHem, y=SetSizeEffect, fill=dat1utr)) +
geom_bar(position=position_dodge(.9), colour="Black", stat="identity") +
geom_errorbar(position=position_dodge(.9), width=.3, aes(ymin=SetSizeEffect-se, ymax=SetSizeEffect+se)) + #can change "se" to "ci" if I want to use 95%ci instead
geom_hline(yintercept=0) +  coord_cartesian(ylim = c(-15, 65)) +
xlab("Distractor Hemifield") + ylab("Set Size Effect (ms)") +
theme(axis.title.x = element_text(face="bold", size=12),
axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
theme(axis.title.y = element_text(face="bold", size=12),
axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
theme(legend.title = element_text(size=11, face="bold")) +
theme(legend.text = element_text(size = 11, face = "bold")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"))
#Sweet, this effect looks the same as the effect in
#Figure 2A of Newman et al. (2014) JoN paper  Which is nice to see.
########################################################################################################################
########################################################################################################################
########################################################################################################################
########################################################################################################################
# Now lets look at modeling the single trial RT data as a function of TargetLoc:
#Since all Monash participants are currently missing genotypes I'll do this
# nesting participants inside dat1utr, and won't worry about Site.
#Also, TargetLocs (1-16) are nested inside TargetHem (left vs. right):
with(data2, isNested(TargetLoc,TargetHem))
#First make a baseline model with random intercepts and no fixed effects:
random_intercepts_only<-lmer(log(RT) ~ 1 + (1 | dat1utr/ID) +(1|TargetHem/TargetLoc) + (1 |SetSize)
+(1|DisplayType), data = data2, na.action = na.omit, REML=FALSE)
#Then we add in the fixed effect of SetSize, etc.:
SetSize<-update(random_intercepts_only, .~. + SetSize)
DisplayType<-update(SetSize, .~. + DisplayType)
TargetLoc<-update(DisplayType, .~. + TargetLoc)
DAT1UTR<-update(TargetLoc, .~. + dat1utr)
CFQ<-update(dat1utr, .~. + CFQ)
CAARS_H<-update(CFQ, .~. + CAARS_H)
library(lme4)
#First make a baseline model with random intercepts and no fixed effects:
random_intercepts_only<-lmer(log(RT) ~ 1 + (1 | dat1utr/ID) +(1|TargetHem/TargetLoc) + (1 |SetSize)
+(1|DisplayType), data = data2, na.action = na.omit, REML=FALSE)
